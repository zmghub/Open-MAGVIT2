seed_everything: true
trainer:
  accelerator: gpu
  strategy: ddp_find_unused_parameters_true
  devices: 8
  num_nodes: 4
  precision: 16-mixed
  max_epochs: 150
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 0
  log_every_n_steps: 100
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "/data/sfs-hpc-mtlab-xm-training/wy42/training/open-magvit2/klgan/checkpoints/20240628"
        save_top_k: -1 # save all checkpoints
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: "/data/sfs-hpc-mtlab-xm-training/wy42/training/open-magvit2/klgan/results/20240628"
      version: "test"
      name:

model:
  class_path: taming.svd.autoencoder_kl_temporal_decoder.AutoencoderKLTemporalDecoder
  init_args:
    block_out_channels:
      - 128
      - 256
      - 512
      - 512
    down_block_types:
      - DownEncoderBlock2D
      - DownEncoderBlock2D
      - DownEncoderBlock2D
      - DownEncoderBlock2D
    latent_channels: 4
    layers_per_block: 2
    regularizer_config:
      target: taming.modules.vqvae.DiagonalGaussianRegularizer
    enable_xformers: true
    enable_gradient_checkpointing: true

data:
  class_path: main.DataModuleFromConfig
  init_args:
    batch_size: 6
    num_workers: 16
    train:
      target: taming.data.imagenet_obs.ImageNetTrain
      params:
        config:
          size: 256
          subset:
    validation:
      target: taming.data.imagenet_obs.ImageNetValidation
      params:
        config:
          size: 256
          subset:
    test:
      target: taming.data.imagenet_obs.ImageNetValidation
      params:
        config:
          size: 256
          subset:

ckpt_path: null # to resume